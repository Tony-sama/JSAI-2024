{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_1hCB04U5PR"
      },
      "source": [
        "# User Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IcTgq2NcINr7"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "SESSIONS_SAMPLE = None\n",
        "MIN_SESSIONS_SIZE = 4\n",
        "MIN_ITEM_OCCURENCE = 1\n",
        "DATASET = \"dataset/case_study_sessions.csv\"\n",
        "\n",
        "# Predictive Models\n",
        "TRAIN_RATIO = 0.8\n",
        "MIN_TEST_SESSIONS_SIZE = 4\n",
        "SRGNN_EPOCHS = 20 # 20\n",
        "TOP_K = 1\n",
        "\n",
        "# Encoding\n",
        "MIN_ATTENTION = 0.25\n",
        "\n",
        "# SR-GNN\n",
        "OUTPUT_FILE = \"tmp/sr-gnn_predictions.csv\"\n",
        "SRGNN_PREDICTION_FILE = \"tmp/docomo_sr-gnn_predictions.csv\"\n",
        "\n",
        "# STAMP\n",
        "STAMP_EPOCHS = 20 #20\n",
        "STAMP_PREDICTION_FILE = \"tmp/docomo_stamp_predictions.csv\"\n",
        "\n",
        "# NARM\n",
        "NARM_EPOCHS = 3 #20\n",
        "NARM_PREDICTION_FILE = \"tmp/docomo_narm_predictions.csv\"\n",
        "\n",
        "# Others\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u41CQvsIlaX"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnrRLVH-Uzbs"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT397ynhUiYg",
        "outputId": "bc9ce627-3d66-47a4-a621-c4d2afd12b41"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import pylfit\n",
        "\n",
        "random.seed(RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de8lk7UAU2mi"
      },
      "source": [
        "# Dataset formating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "dTQipHz3PcHy",
        "outputId": "1f63c490-e390-4a79-f070-3e6d91740b70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12832 sessions\n",
            "Found 12832 sessions of size >= 4\n",
            "Found 12832 sessions with item count >= 1\n",
            "Extracted 12832 from it\n",
            "Unique item ids: 12\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionId</th>\n",
              "      <th>ItemId</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>142646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>145152000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>147744000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>208731081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>208731081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55372</th>\n",
              "      <td>12830</td>\n",
              "      <td>5</td>\n",
              "      <td>225763200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55373</th>\n",
              "      <td>12831</td>\n",
              "      <td>2</td>\n",
              "      <td>162345600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55374</th>\n",
              "      <td>12831</td>\n",
              "      <td>4</td>\n",
              "      <td>218592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55375</th>\n",
              "      <td>12831</td>\n",
              "      <td>3</td>\n",
              "      <td>222825600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55376</th>\n",
              "      <td>12831</td>\n",
              "      <td>5</td>\n",
              "      <td>224121600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55377 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       SessionId  ItemId       Time\n",
              "0              0       1  142646400\n",
              "1              0       2  145152000\n",
              "2              0       3  147744000\n",
              "3              0       6  208731081\n",
              "4              0       7  208731081\n",
              "...          ...     ...        ...\n",
              "55372      12830       5  225763200\n",
              "55373      12831       2  162345600\n",
              "55374      12831       4  218592000\n",
              "55375      12831       3  222825600\n",
              "55376      12831       5  224121600\n",
              "\n",
              "[55377 rows x 3 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialise df\n",
        "df_sessions = pd.read_csv(DATASET)\n",
        "\n",
        "# Standard column names\n",
        "df_sessions.rename(columns={\"UserID\": \"SessionId\", \"ItemID\": \"ItemId\"}, inplace=True)\n",
        "\n",
        "print(\"Found\",df_sessions[\"SessionId\"].nunique(),\"sessions\")\n",
        "\n",
        "# Clean too short sessions\n",
        "df_count = df_sessions.groupby(\"SessionId\").count().reset_index()\n",
        "df_sessions = df_sessions[~df_sessions[\"SessionId\"].isin(list(df_count[df_count[\"Time\"] < MIN_SESSIONS_SIZE][\"SessionId\"].unique()))]\n",
        "df_sessions = df_sessions.sort_values(by=[\"SessionId\", \"Time\"])\n",
        "\n",
        "print(\"Found\",df_sessions[\"SessionId\"].nunique(),\"sessions of size >=\",MIN_SESSIONS_SIZE)\n",
        "\n",
        "# Remove sessions with item with too low occurence\n",
        "df_count = df_sessions.groupby(\"ItemId\").count().reset_index()\n",
        "discard_item = list(df_count[df_count[\"Time\"] < MIN_ITEM_OCCURENCE][\"ItemId\"].unique())\n",
        "discard_sessions = list(df_sessions[df_sessions[\"ItemId\"].isin(discard_item)][\"SessionId\"].unique())\n",
        "df_sessions = df_sessions[~df_sessions[\"SessionId\"].isin(discard_sessions)]\n",
        "\n",
        "print(\"Found\",df_sessions[\"SessionId\"].nunique(),\"sessions with item count >=\",MIN_ITEM_OCCURENCE)\n",
        "\n",
        "# Remove additional sessions\n",
        "if SESSIONS_SAMPLE is not None:\n",
        "    df_sessions = df_sessions[df_sessions[\"SessionId\"].isin(df_sessions[\"SessionId\"].unique()[:SESSIONS_SAMPLE])]\n",
        "\n",
        "print(\"Extracted\",df_sessions[\"SessionId\"].nunique(),\"from it\")\n",
        "\n",
        "\n",
        "nb_item_ids = df_sessions[\"ItemId\"].nunique()\n",
        "print(\"Unique item ids:\", nb_item_ids)\n",
        "\n",
        "df_sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sessions\n",
            "Total: 12832\n",
            "Train: 10265\n",
            "Test: 2567\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionId</th>\n",
              "      <th>ItemId</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>142646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>145152000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>147744000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>208731081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>208731081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55372</th>\n",
              "      <td>12830</td>\n",
              "      <td>5</td>\n",
              "      <td>225763200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55373</th>\n",
              "      <td>12831</td>\n",
              "      <td>2</td>\n",
              "      <td>162345600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55374</th>\n",
              "      <td>12831</td>\n",
              "      <td>4</td>\n",
              "      <td>218592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55375</th>\n",
              "      <td>12831</td>\n",
              "      <td>3</td>\n",
              "      <td>222825600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55376</th>\n",
              "      <td>12831</td>\n",
              "      <td>5</td>\n",
              "      <td>224121600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44300 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       SessionId  ItemId       Time\n",
              "0              0       1  142646400\n",
              "1              0       2  145152000\n",
              "2              0       3  147744000\n",
              "3              0       6  208731081\n",
              "4              0       7  208731081\n",
              "...          ...     ...        ...\n",
              "55372      12830       5  225763200\n",
              "55373      12831       2  162345600\n",
              "55374      12831       4  218592000\n",
              "55375      12831       3  222825600\n",
              "55376      12831       5  224121600\n",
              "\n",
              "[44300 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionId</th>\n",
              "      <th>ItemId</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>76464000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>208223210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>208223210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>216421200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>145411200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55359</th>\n",
              "      <td>12828</td>\n",
              "      <td>6</td>\n",
              "      <td>220826929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55360</th>\n",
              "      <td>12828</td>\n",
              "      <td>9</td>\n",
              "      <td>224600868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55361</th>\n",
              "      <td>12828</td>\n",
              "      <td>9</td>\n",
              "      <td>224605596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55362</th>\n",
              "      <td>12828</td>\n",
              "      <td>9</td>\n",
              "      <td>224605624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55363</th>\n",
              "      <td>12828</td>\n",
              "      <td>9</td>\n",
              "      <td>224605640</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11077 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       SessionId  ItemId       Time\n",
              "16             3       1   76464000\n",
              "17             3       6  208223210\n",
              "18             3       7  208223210\n",
              "19             3      10  216421200\n",
              "44            10       2  145411200\n",
              "...          ...     ...        ...\n",
              "55359      12828       6  220826929\n",
              "55360      12828       9  224600868\n",
              "55361      12828       9  224605596\n",
              "55362      12828       9  224605624\n",
              "55363      12828       9  224605640\n",
              "\n",
              "[11077 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sessions_ids = list(set(df_sessions[\"SessionId\"].unique()))\n",
        "train_sessions = random.sample(sessions_ids, int(TRAIN_RATIO*len(sessions_ids)))\n",
        "\n",
        "df_train = df_sessions[df_sessions[\"SessionId\"].isin(train_sessions)]\n",
        "df_test = df_sessions[~df_sessions[\"SessionId\"].isin(train_sessions)]\n",
        "\n",
        "print(\"Sessions\")\n",
        "print(\"Total:\", len(df_sessions[\"SessionId\"].unique()))\n",
        "print(\"Train:\", len(df_train[\"SessionId\"].unique()))\n",
        "print(\"Test:\", len(df_test[\"SessionId\"].unique()))\n",
        "print()\n",
        "\n",
        "display(df_train)\n",
        "display(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SR-GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10265\n",
            "2567\n",
            "[0 1 2]\n",
            "[ 3 10 13]\n",
            "-- Splitting train set and test set @ 2023-11-30 18:34:36.925969s\n",
            "13\n",
            "13505\n",
            "3376\n",
            "avg length:  4.31553927680798\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import argparse\n",
        "import time\n",
        "import csv\n",
        "import pickle\n",
        "import operator\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "sess_clicks = {}\n",
        "sess_date = {}\n",
        "ctr = 0\n",
        "curid = -1\n",
        "curdate = None\n",
        "\n",
        "for index, data in df_sessions.iterrows():\n",
        "    sessid = data['SessionId']\n",
        "    #if curdate and not curid == sessid:\n",
        "        #date = ''\n",
        "        #date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
        "        #sess_date[curid] = date\n",
        "    curid = sessid\n",
        "    item = int(data['ItemId'])\n",
        "    #curdate = ''\n",
        "    #curdate = data['eventdate']\n",
        "    if sessid in sess_clicks:\n",
        "        sess_clicks[sessid] += [item]\n",
        "    else:\n",
        "        sess_clicks[sessid] = [item]\n",
        "    ctr += 1\n",
        "#date = ''\n",
        "#date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
        "#sess_date[curid] = date\n",
        "\n",
        "tra_sess = df_train[\"SessionId\"].unique()\n",
        "tes_sess = df_test[\"SessionId\"].unique()\n",
        "\n",
        "print(len(tra_sess))    # 186670    # 7966257\n",
        "print(len(tes_sess))    # 15979     # 15324\n",
        "print(tra_sess[:3])\n",
        "print(tes_sess[:3])\n",
        "print(\"-- Splitting train set and test set @ %ss\" % datetime.datetime.now())\n",
        "\n",
        "# Choosing item count >=5 gives approximately the same number of items as reported in paper\n",
        "item_dict = {}\n",
        "# Convert training sessions to sequences and renumber items to start from 1\n",
        "def obtian_tra():\n",
        "    train_ids = []\n",
        "    train_seqs = []\n",
        "    item_ctr = 1\n",
        "    for s in tra_sess:\n",
        "        seq = sess_clicks[s]\n",
        "        outseq = []\n",
        "        for i in seq:\n",
        "            if i in item_dict:\n",
        "                outseq += [item_dict[i]]\n",
        "            else:\n",
        "                outseq += [item_ctr]\n",
        "                item_dict[i] = item_ctr\n",
        "                item_ctr += 1\n",
        "        if len(outseq) < 2:  # Doesn't occur\n",
        "            continue\n",
        "        train_ids += [s]\n",
        "        train_seqs += [outseq]\n",
        "    print(item_ctr)     # 43098, 37484\n",
        "    return train_ids, train_seqs, item_ctr\n",
        "\n",
        "\n",
        "# Convert test sessions to sequences, ignoring items that do not appear in training set\n",
        "def obtian_tes():\n",
        "    test_ids = []\n",
        "    test_seqs = []\n",
        "    for s in tes_sess:\n",
        "        seq = sess_clicks[s]\n",
        "        outseq = []\n",
        "        for i in seq:\n",
        "            if i in item_dict:\n",
        "                outseq += [item_dict[i]]\n",
        "        if len(outseq) < 2:\n",
        "            continue\n",
        "        test_ids += [s]\n",
        "        test_seqs += [outseq]\n",
        "    return test_ids, test_seqs\n",
        "\n",
        "\n",
        "tra_ids, tra_seqs, item_ctr = obtian_tra()\n",
        "tes_ids, tes_seqs = obtian_tes()\n",
        "\n",
        "def process_seqs(iseqs, test=False):\n",
        "    out_seqs = []\n",
        "    labs = []\n",
        "    ids = []\n",
        "    for id, seq in zip(range(len(iseqs)), iseqs):\n",
        "        for i in range(1, len(seq) - MIN_SESSIONS_SIZE + 2):\n",
        "            tar = seq[-i]\n",
        "            labs += [tar]\n",
        "            out_seqs += [seq[:-i]]\n",
        "            ids += [id]\n",
        "    return out_seqs, labs, ids\n",
        "\n",
        "\n",
        "tr_seqs, tr_labs, tr_ids = process_seqs(tra_seqs)\n",
        "te_seqs, te_labs, te_ids = process_seqs(tes_seqs, True)\n",
        "tra = (tr_seqs, tr_labs)\n",
        "tes = (te_seqs, te_labs)\n",
        "print(len(tr_seqs))\n",
        "print(len(te_seqs))\n",
        "all = 0\n",
        "\n",
        "for seq in tra_seqs:\n",
        "    all += len(seq)\n",
        "for seq in tes_seqs:\n",
        "    all += len(seq)\n",
        "print('avg length: ', all/(len(tra_seqs) + len(tes_seqs) * 1.0))\n",
        "\n",
        "#tra\n",
        "#tes\n",
        "#tra_seqs\n",
        "\n",
        "pickle.dump(tra, open('tmp/train.txt', 'wb'))\n",
        "pickle.dump(tes, open('tmp/test.txt', 'wb'))\n",
        "n_node = item_ctr\n",
        "n_node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#display(te_seqs, te_labs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SR-GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(batchSize=100, dataset='sample', epoch=20, hiddenSize=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=3, n_node=13, nonhybrid=False, output_file='tmp/sr-gnn_predictions.csv', patience=10, step=1, test='tmp/test.txt', topk=1, train='tmp/train.txt', valid_portion=0.1, validation=False)\n",
            "Loading training data from tmp/train.txt\n",
            "Loading test data from tmp/test.txt\n",
            "-------------------------------------------------------\n",
            "epoch:  0\n",
            "start training:  2023-11-30 18:34:37.516067\n",
            "[0/136] Loss: 2.4603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[28/136] Loss: 1.4006\n",
            "[56/136] Loss: 0.7597\n",
            "[84/136] Loss: 0.8954\n",
            "[112/136] Loss: 0.9041\n",
            "\tLoss:\t145.244\n",
            "start predicting:  2023-11-30 18:34:39.643140\n",
            "Best Result:\n",
            "\tRecall@1: 78.2879 \tMMR@1: 78.2879 \tEpoch: 0 \tbest: 0\n",
            "-------------------------------------------------------\n",
            "epoch:  1\n",
            "start training:  2023-11-30 18:34:40.061065\n",
            "[0/136] Loss: 0.7217\n",
            "[28/136] Loss: 0.6837\n",
            "[56/136] Loss: 0.6077\n",
            "[84/136] Loss: 0.5822\n",
            "[112/136] Loss: 0.5676\n",
            "\tLoss:\t86.478\n",
            "start predicting:  2023-11-30 18:34:42.172463\n",
            "Best Result:\n",
            "\tRecall@1: 79.7097 \tMMR@1: 79.7097 \tEpoch: 1 \tbest: 1\n",
            "-------------------------------------------------------\n",
            "epoch:  2\n",
            "start training:  2023-11-30 18:34:42.573948\n",
            "[0/136] Loss: 0.5929\n",
            "[28/136] Loss: 0.5631\n",
            "[56/136] Loss: 0.5133\n",
            "[84/136] Loss: 0.3603\n",
            "[112/136] Loss: 0.5707\n",
            "\tLoss:\t79.849\n",
            "start predicting:  2023-11-30 18:34:44.634084\n",
            "Best Result:\n",
            "\tRecall@1: 79.7097 \tMMR@1: 79.7097 \tEpoch: 2 \tbest: 2\n",
            "-------------------------------------------------------\n",
            "epoch:  3\n",
            "start training:  2023-11-30 18:34:45.096259\n",
            "[0/136] Loss: 0.6497\n",
            "[28/136] Loss: 0.5639\n",
            "[56/136] Loss: 0.6540\n",
            "[84/136] Loss: 0.5958\n",
            "[112/136] Loss: 0.5701\n",
            "\tLoss:\t79.011\n",
            "start predicting:  2023-11-30 18:34:47.115623\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  4\n",
            "start training:  2023-11-30 18:34:47.514146\n",
            "[0/136] Loss: 0.5003\n",
            "[28/136] Loss: 0.5147\n",
            "[56/136] Loss: 0.5619\n",
            "[84/136] Loss: 0.6187\n",
            "[112/136] Loss: 0.6488\n",
            "\tLoss:\t79.340\n",
            "start predicting:  2023-11-30 18:34:49.514793\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  5\n",
            "start training:  2023-11-30 18:34:49.922732\n",
            "[0/136] Loss: 0.4402\n",
            "[28/136] Loss: 0.2869\n",
            "[56/136] Loss: 0.5668\n",
            "[84/136] Loss: 0.6646\n",
            "[112/136] Loss: 0.4896\n",
            "\tLoss:\t78.970\n",
            "start predicting:  2023-11-30 18:34:51.959502\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  6\n",
            "start training:  2023-11-30 18:34:52.367793\n",
            "[0/136] Loss: 0.5155\n",
            "[28/136] Loss: 0.5409\n",
            "[56/136] Loss: 0.6409\n",
            "[84/136] Loss: 0.5875\n",
            "[112/136] Loss: 0.6177\n",
            "\tLoss:\t78.272\n",
            "start predicting:  2023-11-30 18:34:54.369471\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  7\n",
            "start training:  2023-11-30 18:34:54.800680\n",
            "[0/136] Loss: 0.5133\n",
            "[28/136] Loss: 0.7025\n",
            "[56/136] Loss: 0.4690\n",
            "[84/136] Loss: 0.5142\n",
            "[112/136] Loss: 0.3566\n",
            "\tLoss:\t77.614\n",
            "start predicting:  2023-11-30 18:34:56.792057\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  8\n",
            "start training:  2023-11-30 18:34:57.186563\n",
            "[0/136] Loss: 0.6654\n",
            "[28/136] Loss: 0.4566\n",
            "[56/136] Loss: 0.4811\n",
            "[84/136] Loss: 0.7410\n",
            "[112/136] Loss: 0.5331\n",
            "\tLoss:\t77.793\n",
            "start predicting:  2023-11-30 18:34:59.212744\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  9\n",
            "start training:  2023-11-30 18:34:59.626104\n",
            "[0/136] Loss: 0.6061\n",
            "[28/136] Loss: 0.6649\n",
            "[56/136] Loss: 0.4428\n",
            "[84/136] Loss: 0.5159\n",
            "[112/136] Loss: 0.3890\n",
            "\tLoss:\t77.844\n",
            "start predicting:  2023-11-30 18:35:01.670796\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  10\n",
            "start training:  2023-11-30 18:35:02.079586\n",
            "[0/136] Loss: 0.5820\n",
            "[28/136] Loss: 0.4970\n",
            "[56/136] Loss: 0.7140\n",
            "[84/136] Loss: 0.5853\n",
            "[112/136] Loss: 0.5029\n",
            "\tLoss:\t78.051\n",
            "start predicting:  2023-11-30 18:35:04.092222\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  11\n",
            "start training:  2023-11-30 18:35:04.522592\n",
            "[0/136] Loss: 0.6104\n",
            "[28/136] Loss: 0.5827\n",
            "[56/136] Loss: 0.5993\n",
            "[84/136] Loss: 0.4874\n",
            "[112/136] Loss: 0.5648\n",
            "\tLoss:\t77.512\n",
            "start predicting:  2023-11-30 18:35:06.555151\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  12\n",
            "start training:  2023-11-30 18:35:06.980065\n",
            "[0/136] Loss: 0.4869\n",
            "[28/136] Loss: 0.4339\n",
            "[56/136] Loss: 0.5571\n",
            "[84/136] Loss: 0.5255\n",
            "[112/136] Loss: 0.4927\n",
            "\tLoss:\t78.386\n",
            "start predicting:  2023-11-30 18:35:09.005031\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "epoch:  13\n",
            "start training:  2023-11-30 18:35:09.401001\n",
            "[0/136] Loss: 0.4084\n",
            "[28/136] Loss: 0.5934\n",
            "[56/136] Loss: 0.4523\n",
            "[84/136] Loss: 0.5670\n",
            "[112/136] Loss: 0.5340\n",
            "\tLoss:\t78.046\n",
            "start predicting:  2023-11-30 18:35:11.398995\n",
            "Best Result:\n",
            "\tRecall@1: 79.8874 \tMMR@1: 79.8874 \tEpoch: 3 \tbest: 3\n",
            "-------------------------------------------------------\n",
            "Run time: 34.293298 s\n"
          ]
        }
      ],
      "source": [
        "%run algorithms/SR-GNN/pytorch_code/main.py --train tmp/train.txt --test tmp/test.txt --n_node {n_node} --epoch {SRGNN_EPOCHS} --topk {TOP_K} --output_file {OUTPUT_FILE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract predictions with attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 1, 2: 2, 3: 3, 4: 6, 5: 7, 6: 10, 7: 4, 8: 5, 9: 9, 10: 11, 11: 12, 12: 8}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_map = {v: k for k, v in item_dict.items()}\n",
        "inv_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Expected</th>\n",
              "      <th>Model_input</th>\n",
              "      <th>Model_attention</th>\n",
              "      <th>Model_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>[1, 6, 7]</td>\n",
              "      <td>[-3.7130167484283447, -3.8705673217773438, -4....</td>\n",
              "      <td>[2, 10, 4, 9, 12, 1, 11, 3, 8, 5, 6, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[-3.1652047634124756, -3.1256532669067383, -3....</td>\n",
              "      <td>[7, 1, 9, 8, 10, 4, 12, 11, 6, 2, 5, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[-3.1652047634124756, -3.1256532669067383, -3....</td>\n",
              "      <td>[7, 1, 9, 8, 10, 4, 12, 11, 6, 2, 5, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[-3.1652047634124756, -3.1256532669067383, -3....</td>\n",
              "      <td>[7, 1, 9, 8, 10, 4, 12, 11, 6, 2, 5, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[-3.1652047634124756, -3.1256532669067383, -3....</td>\n",
              "      <td>[7, 1, 9, 8, 10, 4, 12, 11, 6, 2, 5, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3371</th>\n",
              "      <td>6</td>\n",
              "      <td>[2, 3, 7]</td>\n",
              "      <td>[-3.5456700325012207, -3.7342920303344727, -3....</td>\n",
              "      <td>[6, 1, 10, 4, 7, 9, 5, 2, 12, 11, 3, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3372</th>\n",
              "      <td>6</td>\n",
              "      <td>[2, 3, 7]</td>\n",
              "      <td>[-3.5456700325012207, -3.7342920303344727, -3....</td>\n",
              "      <td>[6, 1, 10, 4, 7, 9, 5, 2, 12, 11, 3, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3373</th>\n",
              "      <td>4</td>\n",
              "      <td>[7, 6, 5]</td>\n",
              "      <td>[-3.5796241760253906, -3.9678800106048584, -3....</td>\n",
              "      <td>[4, 10, 1, 12, 9, 2, 3, 11, 8, 7, 5, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3374</th>\n",
              "      <td>9</td>\n",
              "      <td>[6, 9, 9, 9]</td>\n",
              "      <td>[-2.7884278297424316, -2.856088638305664, -2.8...</td>\n",
              "      <td>[9, 8, 12, 11, 4, 10, 7, 2, 5, 1, 6, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3375</th>\n",
              "      <td>9</td>\n",
              "      <td>[6, 9, 9]</td>\n",
              "      <td>[-2.7884278297424316, -2.856088638305664, -2.8...</td>\n",
              "      <td>[9, 8, 12, 11, 4, 7, 10, 2, 1, 5, 6, 3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3376 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Expected   Model_input  \\\n",
              "0           10     [1, 6, 7]   \n",
              "1            7     [2, 3, 6]   \n",
              "2            7     [2, 3, 6]   \n",
              "3            7     [2, 3, 6]   \n",
              "4            7     [2, 3, 6]   \n",
              "...        ...           ...   \n",
              "3371         6     [2, 3, 7]   \n",
              "3372         6     [2, 3, 7]   \n",
              "3373         4     [7, 6, 5]   \n",
              "3374         9  [6, 9, 9, 9]   \n",
              "3375         9     [6, 9, 9]   \n",
              "\n",
              "                                        Model_attention  \\\n",
              "0     [-3.7130167484283447, -3.8705673217773438, -4....   \n",
              "1     [-3.1652047634124756, -3.1256532669067383, -3....   \n",
              "2     [-3.1652047634124756, -3.1256532669067383, -3....   \n",
              "3     [-3.1652047634124756, -3.1256532669067383, -3....   \n",
              "4     [-3.1652047634124756, -3.1256532669067383, -3....   \n",
              "...                                                 ...   \n",
              "3371  [-3.5456700325012207, -3.7342920303344727, -3....   \n",
              "3372  [-3.5456700325012207, -3.7342920303344727, -3....   \n",
              "3373  [-3.5796241760253906, -3.9678800106048584, -3....   \n",
              "3374  [-2.7884278297424316, -2.856088638305664, -2.8...   \n",
              "3375  [-2.7884278297424316, -2.856088638305664, -2.8...   \n",
              "\n",
              "                             Model_prediction  \n",
              "0     [2, 10, 4, 9, 12, 1, 11, 3, 8, 5, 6, 7]  \n",
              "1     [7, 1, 9, 8, 10, 4, 12, 11, 6, 2, 5, 3]  \n",
              "2     [7, 1, 9, 8, 10, 4, 12, 11, 6, 2, 5, 3]  \n",
              "3     [7, 1, 9, 8, 10, 4, 12, 11, 6, 2, 5, 3]  \n",
              "4     [7, 1, 9, 8, 10, 4, 12, 11, 6, 2, 5, 3]  \n",
              "...                                       ...  \n",
              "3371  [6, 1, 10, 4, 7, 9, 5, 2, 12, 11, 3, 8]  \n",
              "3372  [6, 1, 10, 4, 7, 9, 5, 2, 12, 11, 3, 8]  \n",
              "3373  [4, 10, 1, 12, 9, 2, 3, 11, 8, 7, 5, 6]  \n",
              "3374  [9, 8, 12, 11, 4, 10, 7, 2, 5, 1, 6, 3]  \n",
              "3375  [9, 8, 12, 11, 4, 7, 10, 2, 1, 5, 6, 3]  \n",
              "\n",
              "[3376 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_preds = pd.read_csv(OUTPUT_FILE, index_col=\"SessionId\")\n",
        "\n",
        "#display(df_preds)\n",
        "\n",
        "# Decode item ids\n",
        "df_preds[\"Input\"] = [[inv_map[j] for j in i] for i in te_seqs]\n",
        "df_preds[\"Target\"] = df_preds[\"Target\"].apply(lambda x: inv_map[x])\n",
        "\n",
        "# Normalize attention\n",
        "predictions = []\n",
        "attentions = []\n",
        "hit_rate = []\n",
        "for idx, row in df_preds.iterrows():\n",
        "    prediction = [inv_map[int(i)] for i in row[\"Predictions\"].replace(\"[\",\"\").replace(\"]\",\"\").split(\", \")]\n",
        "    predictions += [prediction]\n",
        "\n",
        "df_preds[\"Predictions\"] = predictions\n",
        "\n",
        "# Save for EDA and LFIT notebook\n",
        "df_out = pd.DataFrame()\n",
        "df_out[\"Expected\"] = df_preds[\"Target\"]\n",
        "df_out.reset_index(inplace=True)\n",
        "df_out.drop(\"SessionId\",axis=1,inplace=True)\n",
        "df_out[\"Model_input\"] = df_preds[\"Input\"]\n",
        "df_out[\"Model_attention\"] = df_preds[\"Attention\"]\n",
        "df_out[\"Model_prediction\"] = df_preds[\"Predictions\"]\n",
        "df_out.to_csv(SRGNN_PREDICTION_FILE,index=False)\n",
        "display(df_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STAMP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
            "c:\\Users\\Tony\\AppData\\Local\\anaconda3\\envs\\CAISE2023-STAMP\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
            "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
            "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
            "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
            "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 16693321766870628439)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# STAMP\n",
        "from algorithms.STAMP.model.STAMP import Seq2SeqAttNN\n",
        "from algorithms.STAMP.util.batcher.equal_len.batcher_p import batcher\n",
        "\n",
        "# NARM\n",
        "from algorithms.NARM.narm import NARM\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "tf.random.set_random_seed(RANDOM_SEED)\n",
        "#tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  devices = sess.list_devices()\n",
        "devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "stamp\n",
            "GPU: False\n",
            "reload the datasets.\n",
            "rsc15_64\n",
            "read finish\n",
            "sort finish\n",
            "list finish\n",
            "I am reading\n",
            "id: 10264\n",
            "session_id: 12831\n",
            "items: [2, 7, 3, 8]\n",
            "click_items: [2, 4, 3, 5]\n",
            "out: [7, 3, 8]\n",
            "in: [2, 7, 3]\n",
            "label: []\n",
            "\n",
            "13\n",
            "read finish\n",
            "sort finish\n",
            "list finish\n",
            "I am reading\n",
            "id: 2566\n",
            "session_id: 12828\n",
            "items: [4, 9, 9, 9, 9]\n",
            "click_items: [6, 9, 9, 9, 9]\n",
            "out: [9, 9, 9, 9]\n",
            "in: [4, 9, 9, 9]\n",
            "label: []\n",
            "\n",
            "13\n",
            "-----\n",
            "Epoch0\tloss: 1.871697\ttime: 1.4365754127502441s\n",
            "Epoch1\tloss: 1.132598\ttime: 1.3490056991577148s\n",
            "Epoch2\tloss: 0.987764\ttime: 1.3671607971191406s\n",
            "Epoch3\tloss: 0.954674\ttime: 1.3280353546142578s\n",
            "Epoch4\tloss: 0.902993\ttime: 1.3680682182312012s\n",
            "Epoch5\tloss: 0.913747\ttime: 1.2980358600616455s\n",
            "Epoch6\tloss: 0.904447\ttime: 1.408010482788086s\n",
            "Epoch7\tloss: 0.886487\ttime: 1.298856496810913s\n",
            "Epoch8\tloss: 0.883468\ttime: 1.383084774017334s\n",
            "Epoch9\tloss: 0.871365\ttime: 1.3576443195343018s\n",
            "Epoch10\tloss: 0.860527\ttime: 1.3852713108062744s\n",
            "Epoch11\tloss: 0.881752\ttime: 1.285630702972412s\n",
            "Epoch12\tloss: 0.881961\ttime: 1.4532232284545898s\n",
            "Epoch13\tloss: 0.865413\ttime: 1.299398422241211s\n",
            "Epoch14\tloss: 0.887296\ttime: 1.4140946865081787s\n",
            "Epoch15\tloss: 0.868610\ttime: 1.3284037113189697s\n",
            "Epoch16\tloss: 0.869704\ttime: 1.380469799041748s\n",
            "Epoch17\tloss: 0.864105\ttime: 1.3560574054718018s\n",
            "Epoch18\tloss: 0.881658\ttime: 1.3739736080169678s\n",
            "Epoch19\tloss: 0.874186\ttime: 1.2895290851593018s\n"
          ]
        }
      ],
      "source": [
        "model = Seq2SeqAttNN(n_epochs=STAMP_EPOCHS, model_save_path=\"\", model_path=\"\", is_save=True)\n",
        "model.fit(df_train,df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([1],\n",
              " array([2.757456], dtype=float32),\n",
              " 1    -3.084484\n",
              " 2     3.616011\n",
              " 3    -0.862608\n",
              " 6     1.639037\n",
              " 7     1.969161\n",
              " 10    0.586589\n",
              " 4     0.196670\n",
              " 5    -1.530922\n",
              " 9    -1.620706\n",
              " 11   -2.558436\n",
              " 12   -3.767925\n",
              " 8    -1.655533\n",
              " Name: 0, dtype: float32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def stamp_predict_next(model, session_id, input_item_id):\n",
        "  '''\n",
        "  Gives prediction scores for a selected item in a selected session.\n",
        "  The self.s variable allow to shift the items in the selected session.\n",
        "  Parameters\n",
        "  --------\n",
        "  session_id : int\n",
        "      Contains the session ID.\n",
        "  input_item_id : int\n",
        "      Contains the item ID of the events of the session.\n",
        "  Returns\n",
        "  --------\n",
        "  out : (input, attention, predictions)\n",
        "      input: list of int\n",
        "        The input session of the model\n",
        "      attention: list of int\n",
        "        The attention layer value of the model\n",
        "      predictions: pandas.Serie\n",
        "        Prediction scores given the input_item_id and session_id for the next item.\n",
        "        Columns: 1 column containing the scores; rows: items. Rows are indexed by the item IDs.'''\n",
        "\n",
        "  sample = [x for x in model.test_data.samples if x.session_id == session_id]\n",
        "  #if model.old_session_id != session_id:\n",
        "  #    model.s = 0\n",
        "  \n",
        "  # DBG\n",
        "  #print(input_item_id)\n",
        "  model.s = input_item_id\n",
        "\n",
        "  c_loss = []\n",
        "  bt = batcher(\n",
        "      samples=sample,\n",
        "      class_num=model.n_items,\n",
        "      random=False\n",
        "  )\n",
        "\n",
        "  while bt.has_next():  # batch round.\n",
        "      batch_data = bt.next_batch()\n",
        "\n",
        "      tmp_in_data = batch_data['in_idxes']\n",
        "      tmp_out_data = batch_data['out_idxes']\n",
        "      tmp_batch_ids = batch_data['batch_ids']\n",
        "      # for s in range(len(tmp_in_data[0])):\n",
        "      batch_in = []\n",
        "      batch_out = []\n",
        "      batch_last = []\n",
        "      batch_seq_l = []\n",
        "      for tmp_in, tmp_out in zip(tmp_in_data, tmp_out_data):\n",
        "          _in = tmp_in[model.s]\n",
        "          _out = tmp_out[model.s] - 1\n",
        "          batch_last.append(_in)\n",
        "          batch_in.append(tmp_in[:model.s + 1])\n",
        "          batch_out.append(_out)\n",
        "          batch_seq_l.append(model.s + 1)\n",
        "      feed_dict = {\n",
        "          model.inputs: batch_in,\n",
        "          model.last_inputs: batch_last,\n",
        "          model.lab_input: batch_out,\n",
        "          model.sequence_length: batch_seq_l\n",
        "\n",
        "      }\n",
        "      \n",
        "\n",
        "      preds, loss, alpha = model.sess.run([model.softmax_input, model.loss, model.alph],feed_dict=feed_dict)\n",
        "      model.test_data.pack_ext_matrix('alpha', alpha, tmp_batch_ids)\n",
        "      c_loss += list(loss)\n",
        "      rev_map = {v: k for k, v in model.mappingitem2idx.items()}\n",
        "      return [rev_map[i] for i in feed_dict[model.inputs][0]], alpha[0][0], pd.DataFrame(data=np.asanyarray(preds.reshape(len(preds[0]), 1)), index=list(model.mappingitem2idx.keys()))[0]\n",
        "\n",
        "stamp_predict_next(model, session_id=df_test.iloc[0][\"SessionId\"], input_item_id=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[10,\n",
              "  [1, 6, 7],\n",
              "  array([3.5233486, 4.3522983, 4.5918145], dtype=float32),\n",
              "  1    -0.757491\n",
              "  2     1.888521\n",
              "  3    -0.737072\n",
              "  6    -2.527257\n",
              "  7    -2.725819\n",
              "  10    0.617299\n",
              "  4     1.622910\n",
              "  5    -1.104082\n",
              "  9     0.257805\n",
              "  11   -1.132285\n",
              "  12    0.368262\n",
              "  8    -2.480730\n",
              "  Name: 0, dtype: float32],\n",
              " [7,\n",
              "  [2, 3, 6],\n",
              "  array([4.0930343, 4.648213 , 4.131812 ], dtype=float32),\n",
              "  1     2.248339\n",
              "  2    -3.191094\n",
              "  3    -1.957756\n",
              "  6    -1.785464\n",
              "  7     5.277082\n",
              "  10    0.592810\n",
              "  4     0.022180\n",
              "  5    -2.986837\n",
              "  9     2.021633\n",
              "  11   -5.117090\n",
              "  12    0.307857\n",
              "  8     1.012788\n",
              "  Name: 0, dtype: float32]]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = []\n",
        "for index, row in df_test.groupby('SessionId', observed=True)['ItemId'].apply(list).reset_index().iterrows(): #df_test.groupby(\"SessionId\", observed=True).count().reset_index().iterrows():\n",
        "  session_id = row[\"SessionId\"]\n",
        "  session_length = len(row[\"ItemId\"])\n",
        "  # Subsessions\n",
        "  for i in range(MIN_TEST_SESSIONS_SIZE-2, session_length-1):\n",
        "    predictions.append([row[\"ItemId\"][i+1]] + list(stamp_predict_next(model, session_id=session_id, input_item_id=i)))\n",
        "\n",
        "predictions[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Expected</th>\n",
              "      <th>Model_input</th>\n",
              "      <th>Model_attention</th>\n",
              "      <th>Model_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>[1, 6, 7]</td>\n",
              "      <td>[3.5233486, 4.3522983, 4.5918145]</td>\n",
              "      <td>[2, 4, 10, 12, 9, 3, 1, 5, 11, 8, 6, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[4.0930343, 4.648213, 4.131812]</td>\n",
              "      <td>[7, 1, 9, 8, 10, 12, 4, 6, 3, 5, 2, 11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[4.0930343, 4.648213, 4.131812]</td>\n",
              "      <td>[7, 1, 9, 8, 10, 12, 4, 6, 3, 5, 2, 11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[4.0930343, 4.648213, 4.131812]</td>\n",
              "      <td>[7, 1, 9, 8, 10, 12, 4, 6, 3, 5, 2, 11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[4.0930343, 4.648213, 4.131812]</td>\n",
              "      <td>[7, 1, 9, 8, 10, 12, 4, 6, 3, 5, 2, 11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3371</th>\n",
              "      <td>6</td>\n",
              "      <td>[2, 3, 7]</td>\n",
              "      <td>[4.3466716, 4.851342, 4.636951]</td>\n",
              "      <td>[6, 1, 4, 10, 3, 7, 11, 2, 9, 5, 8, 12]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3372</th>\n",
              "      <td>6</td>\n",
              "      <td>[2, 3, 7]</td>\n",
              "      <td>[4.3466716, 4.851342, 4.636951]</td>\n",
              "      <td>[6, 1, 4, 10, 3, 7, 11, 2, 9, 5, 8, 12]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3373</th>\n",
              "      <td>4</td>\n",
              "      <td>[7, 6, 5]</td>\n",
              "      <td>[4.818439, 4.5853662, 4.9188433]</td>\n",
              "      <td>[4, 1, 12, 9, 8, 2, 3, 7, 10, 11, 6, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3374</th>\n",
              "      <td>9</td>\n",
              "      <td>[6, 9, 9]</td>\n",
              "      <td>[4.530071, 4.525478, 4.525478]</td>\n",
              "      <td>[9, 8, 4, 1, 7, 2, 11, 5, 12, 6, 3, 10]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3375</th>\n",
              "      <td>9</td>\n",
              "      <td>[6, 9, 9, 9]</td>\n",
              "      <td>[4.487334, 4.484192, 4.484192, 4.484192]</td>\n",
              "      <td>[9, 8, 4, 7, 1, 2, 11, 5, 6, 12, 3, 10]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3376 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Expected   Model_input                           Model_attention  \\\n",
              "0           10     [1, 6, 7]         [3.5233486, 4.3522983, 4.5918145]   \n",
              "1            7     [2, 3, 6]           [4.0930343, 4.648213, 4.131812]   \n",
              "2            7     [2, 3, 6]           [4.0930343, 4.648213, 4.131812]   \n",
              "3            7     [2, 3, 6]           [4.0930343, 4.648213, 4.131812]   \n",
              "4            7     [2, 3, 6]           [4.0930343, 4.648213, 4.131812]   \n",
              "...        ...           ...                                       ...   \n",
              "3371         6     [2, 3, 7]           [4.3466716, 4.851342, 4.636951]   \n",
              "3372         6     [2, 3, 7]           [4.3466716, 4.851342, 4.636951]   \n",
              "3373         4     [7, 6, 5]          [4.818439, 4.5853662, 4.9188433]   \n",
              "3374         9     [6, 9, 9]            [4.530071, 4.525478, 4.525478]   \n",
              "3375         9  [6, 9, 9, 9]  [4.487334, 4.484192, 4.484192, 4.484192]   \n",
              "\n",
              "                             Model_prediction  \n",
              "0     [2, 4, 10, 12, 9, 3, 1, 5, 11, 8, 6, 7]  \n",
              "1     [7, 1, 9, 8, 10, 12, 4, 6, 3, 5, 2, 11]  \n",
              "2     [7, 1, 9, 8, 10, 12, 4, 6, 3, 5, 2, 11]  \n",
              "3     [7, 1, 9, 8, 10, 12, 4, 6, 3, 5, 2, 11]  \n",
              "4     [7, 1, 9, 8, 10, 12, 4, 6, 3, 5, 2, 11]  \n",
              "...                                       ...  \n",
              "3371  [6, 1, 4, 10, 3, 7, 11, 2, 9, 5, 8, 12]  \n",
              "3372  [6, 1, 4, 10, 3, 7, 11, 2, 9, 5, 8, 12]  \n",
              "3373  [4, 1, 12, 9, 8, 2, 3, 7, 10, 11, 6, 5]  \n",
              "3374  [9, 8, 4, 1, 7, 2, 11, 5, 12, 6, 3, 10]  \n",
              "3375  [9, 8, 4, 7, 1, 2, 11, 5, 6, 12, 3, 10]  \n",
              "\n",
              "[3376 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def predictions_to_dataframe(predictions):\n",
        "    df_preds = pd.DataFrame(predictions, columns=['Expected', 'Model_input', 'Model_attention', 'Model_prediction'])\n",
        "    df_preds[\"Expected\"] = [a for a,b,c,d in predictions]\n",
        "    df_preds[\"Model_input\"] = [list(b) for a,b,c,d in predictions]\n",
        "    df_preds[\"Model_attention\"] = [list(c) for a,b,c,d in predictions]\n",
        "    df_preds[\"Model_prediction\"] = [list(d.sort_values(ascending=False).index) for a,b,c,d in predictions]\n",
        "    #df_preds[\"HIT_\"+str(TOP_K)] = [float(i in df_preds[\"Model_prediction\"].iloc[idx][:TOP_K]) for idx, i in enumerate(df_preds[\"Expected\"].values)]\n",
        "    #df_preds[\"HIT_\"+str(TOP_K)] = [float(i in df_preds[\"Model_prediction\"].iloc[idx][:TOP_K]) for idx, i in enumerate(df_preds[\"Expected\"].values)]\n",
        "    return df_preds\n",
        "\n",
        "df_preds = predictions_to_dataframe(predictions)\n",
        "display(df_preds)\n",
        "\n",
        "df_preds.to_csv(STAMP_PREDICTION_FILE,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model options {'test_size': -1, 'reload_model': None, 'use_dropout': True, 'valid_batch_size': 512, 'batch_size': 512, 'is_save': False, 'is_valid': True, 'saveto': 'gru_model.npz', 'encoder': 'gru', 'n_items': 13, 'lrate': 0.001, 'dispFreq': 10000, 'max_epochs': 3, 'patience': 5, 'hidden_units': 100, 'dim_proj': 100, 'self': <algorithms.NARM.narm.NARM object at 0x0000016B854718D0>}\n",
            "Loading data\n",
            "Building model\n",
            "Optimization\n",
            "30632 train examples\n",
            "3403 valid examples\n",
            "Best perfomance updated!\n",
            "Valid Recall@20: 1.0    Valid Mrr@20: 0.8643077422463258\n",
            "Seen 30632 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "This epoch took 4315.2s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best perfomance updated!\n",
            "Valid Recall@20: 1.0    Valid Mrr@20: 0.8680081640043439\n",
            "Seen 30632 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "This epoch took 4319.5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best perfomance updated!\n",
            "Valid Recall@20: 1.0    Valid Mrr@20: 0.8689702109037989\n",
            "Seen 30632 samples\n",
            "=================Best performance=================\n",
            "Valid Recall@20: nan    Valid Mrr@20: nan\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "This epoch took 4213.4s\n"
          ]
        }
      ],
      "source": [
        "model = NARM(epochs=NARM_EPOCHS,session_key='SessionId', item_key='ItemId')\n",
        "model.fit(df_train,df_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([1, 1, 1, 1],\n",
              " array([0.43813477, 0.23418211, 0.17892223, 0.14876089]),\n",
              " 1     0.000009\n",
              " 2     0.937193\n",
              " 3     0.005729\n",
              " 6     0.024083\n",
              " 7     0.015368\n",
              " 10    0.014318\n",
              " 4     0.002655\n",
              " 5     0.000186\n",
              " 9     0.000043\n",
              " 11    0.000079\n",
              " 12    0.000061\n",
              " 8     0.000172\n",
              " dtype: float64)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def narm_predict_next(model, session):\n",
        "    '''\n",
        "    Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
        "            \n",
        "    Parameters\n",
        "    --------\n",
        "    session_id : int or string\n",
        "        The session IDs of the event.\n",
        "    input_item_id : int or string\n",
        "        The item ID of the event.\n",
        "    predict_for_item_ids : 1D array\n",
        "        IDs of items for which the network should give prediction scores. Every ID must be in the set of item IDs of the training set.\n",
        "        \n",
        "    Returns\n",
        "    --------\n",
        "    out : pandas.Series\n",
        "        Prediction scores for selected items on how likely to be the next item of this session. Indexed by the item IDs.\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    #model.session = session_id\n",
        "    model.session_items = list(session)\n",
        "    \n",
        "    x = [model.itemmap[model.session_items].values]\n",
        "    y = x\n",
        "    \n",
        "    x, mask, y = model.prepare_data(x,y)\n",
        "    preds = model.pred_function(x, mask)\n",
        "    attention = model.attention(x, mask)[0]\n",
        "\n",
        "    return session, attention, pd.Series(data=preds[0][1:], index=model.itemmap.index)\n",
        "\n",
        "narm_predict_next(model, [1,1,1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[10,\n",
              "  [1, 6, 7],\n",
              "  array([0.33919114, 0.37246001, 0.28834885]),\n",
              "  1     0.010914\n",
              "  2     0.624937\n",
              "  3     0.068836\n",
              "  6     0.002471\n",
              "  7     0.005747\n",
              "  10    0.148283\n",
              "  4     0.105451\n",
              "  5     0.003280\n",
              "  9     0.009637\n",
              "  11    0.011189\n",
              "  12    0.005197\n",
              "  8     0.002264\n",
              "  dtype: float64],\n",
              " [7,\n",
              "  [2, 3, 6],\n",
              "  array([0.22606462, 0.60602971, 0.16790567]),\n",
              "  1     0.004677\n",
              "  2     0.000083\n",
              "  3     0.000098\n",
              "  6     0.002088\n",
              "  7     0.978083\n",
              "  10    0.003283\n",
              "  4     0.004192\n",
              "  5     0.000298\n",
              "  9     0.004977\n",
              "  11    0.000174\n",
              "  12    0.000620\n",
              "  8     0.001264\n",
              "  dtype: float64]]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = []\n",
        "for index, row in df_test.groupby('SessionId', observed=True)['ItemId'].apply(list).reset_index().iterrows(): #df_test.groupby(\"SessionId\", observed=True).count().reset_index().iterrows():\n",
        "  session_id = row[\"SessionId\"]\n",
        "  session_length = len(row[\"ItemId\"])\n",
        "  # Subsessions\n",
        "  for i in range(MIN_TEST_SESSIONS_SIZE-2, session_length-1):\n",
        "    predictions.append([row[\"ItemId\"][i+1]] + list(narm_predict_next(model,row[\"ItemId\"][:i+1])))\n",
        "\n",
        "predictions[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Expected</th>\n",
              "      <th>Model_input</th>\n",
              "      <th>Model_attention</th>\n",
              "      <th>Model_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>[1, 6, 7]</td>\n",
              "      <td>[0.339191144203947, 0.3724600103787826, 0.2883...</td>\n",
              "      <td>[2, 10, 4, 3, 11, 1, 9, 7, 12, 5, 6, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[0.22606461943432452, 0.606029710447257, 0.167...</td>\n",
              "      <td>[7, 9, 1, 4, 10, 6, 8, 12, 5, 11, 3, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[0.22606461943432452, 0.606029710447257, 0.167...</td>\n",
              "      <td>[7, 9, 1, 4, 10, 6, 8, 12, 5, 11, 3, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[0.22606461943432452, 0.606029710447257, 0.167...</td>\n",
              "      <td>[7, 9, 1, 4, 10, 6, 8, 12, 5, 11, 3, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>[2, 3, 6]</td>\n",
              "      <td>[0.22606461943432452, 0.606029710447257, 0.167...</td>\n",
              "      <td>[7, 9, 1, 4, 10, 6, 8, 12, 5, 11, 3, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3371</th>\n",
              "      <td>6</td>\n",
              "      <td>[2, 3, 7]</td>\n",
              "      <td>[0.2324626796950567, 0.6231815080922732, 0.144...</td>\n",
              "      <td>[1, 10, 6, 4, 3, 7, 5, 11, 8, 9, 2, 12]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3372</th>\n",
              "      <td>6</td>\n",
              "      <td>[2, 3, 7]</td>\n",
              "      <td>[0.2324626796950567, 0.6231815080922732, 0.144...</td>\n",
              "      <td>[1, 10, 6, 4, 3, 7, 5, 11, 8, 9, 2, 12]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3373</th>\n",
              "      <td>4</td>\n",
              "      <td>[7, 6, 5]</td>\n",
              "      <td>[0.10122615086426462, 0.13078626627339607, 0.7...</td>\n",
              "      <td>[4, 10, 1, 3, 9, 2, 11, 7, 12, 6, 8, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3374</th>\n",
              "      <td>9</td>\n",
              "      <td>[6, 9, 9]</td>\n",
              "      <td>[0.013656520003575513, 0.3182928013702186, 0.6...</td>\n",
              "      <td>[9, 8, 12, 11, 5, 4, 1, 10, 2, 7, 6, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3375</th>\n",
              "      <td>9</td>\n",
              "      <td>[6, 9, 9, 9]</td>\n",
              "      <td>[0.008012529226919245, 0.1867481886329141, 0.3...</td>\n",
              "      <td>[9, 8, 12, 11, 5, 4, 1, 10, 2, 6, 7, 3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3376 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Expected   Model_input  \\\n",
              "0           10     [1, 6, 7]   \n",
              "1            7     [2, 3, 6]   \n",
              "2            7     [2, 3, 6]   \n",
              "3            7     [2, 3, 6]   \n",
              "4            7     [2, 3, 6]   \n",
              "...        ...           ...   \n",
              "3371         6     [2, 3, 7]   \n",
              "3372         6     [2, 3, 7]   \n",
              "3373         4     [7, 6, 5]   \n",
              "3374         9     [6, 9, 9]   \n",
              "3375         9  [6, 9, 9, 9]   \n",
              "\n",
              "                                        Model_attention  \\\n",
              "0     [0.339191144203947, 0.3724600103787826, 0.2883...   \n",
              "1     [0.22606461943432452, 0.606029710447257, 0.167...   \n",
              "2     [0.22606461943432452, 0.606029710447257, 0.167...   \n",
              "3     [0.22606461943432452, 0.606029710447257, 0.167...   \n",
              "4     [0.22606461943432452, 0.606029710447257, 0.167...   \n",
              "...                                                 ...   \n",
              "3371  [0.2324626796950567, 0.6231815080922732, 0.144...   \n",
              "3372  [0.2324626796950567, 0.6231815080922732, 0.144...   \n",
              "3373  [0.10122615086426462, 0.13078626627339607, 0.7...   \n",
              "3374  [0.013656520003575513, 0.3182928013702186, 0.6...   \n",
              "3375  [0.008012529226919245, 0.1867481886329141, 0.3...   \n",
              "\n",
              "                             Model_prediction  \n",
              "0     [2, 10, 4, 3, 11, 1, 9, 7, 12, 5, 6, 8]  \n",
              "1     [7, 9, 1, 4, 10, 6, 8, 12, 5, 11, 3, 2]  \n",
              "2     [7, 9, 1, 4, 10, 6, 8, 12, 5, 11, 3, 2]  \n",
              "3     [7, 9, 1, 4, 10, 6, 8, 12, 5, 11, 3, 2]  \n",
              "4     [7, 9, 1, 4, 10, 6, 8, 12, 5, 11, 3, 2]  \n",
              "...                                       ...  \n",
              "3371  [1, 10, 6, 4, 3, 7, 5, 11, 8, 9, 2, 12]  \n",
              "3372  [1, 10, 6, 4, 3, 7, 5, 11, 8, 9, 2, 12]  \n",
              "3373  [4, 10, 1, 3, 9, 2, 11, 7, 12, 6, 8, 5]  \n",
              "3374  [9, 8, 12, 11, 5, 4, 1, 10, 2, 7, 6, 3]  \n",
              "3375  [9, 8, 12, 11, 5, 4, 1, 10, 2, 6, 7, 3]  \n",
              "\n",
              "[3376 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_preds = predictions_to_dataframe(predictions)\n",
        "display(df_preds)\n",
        "\n",
        "df_preds.to_csv(NARM_PREDICTION_FILE, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c1a56909cdf8a58e1cb21bc2ed84e4cbd7df73ff0900741fb1e4be8e6a358561"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
